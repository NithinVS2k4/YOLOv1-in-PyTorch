{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dcTXwAlLRj4Y"
      },
      "outputs": [],
      "source": [
        "from torch import nn, save, load, argmax, no_grad\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = datasets.CIFAR10(root='data',download=True,train=True,transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "]))\n",
        "train_dataset = DataLoader(train,batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWwitRsJQe3T",
        "outputId": "89cdadaf-271b-4e58-bac1-e5c6ffd78969"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:06<00:00, 27169381.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ImageClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 4 * 4, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),  # Regularization\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 10)  # Output layer for CIFAR-10\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "7Dl-Y5etRFzO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' # cuda for gpu\n",
        "\n",
        "clf = ImageClassifier().to(device) #set to \"cpu\" if no gpu; clf ==> Classifier\n",
        "opt = Adam(clf.parameters(), lr=1e-3, weight_decay = 1e-4)  # lr ==> learning rate; opt ==> Optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "SD1JD7pcUX7i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataset))\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    clf.train()\n",
        "    avg_loss = 0\n",
        "    for batch_num,batch in enumerate(train_dataset):\n",
        "        X,y = batch\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        y_pred = clf(X)\n",
        "        loss = loss_fn(y_pred,y)\n",
        "\n",
        "        #Zero out the previous gradients\n",
        "        opt.zero_grad()\n",
        "\n",
        "        #Calculate backwards gradients\n",
        "        loss.backward()\n",
        "\n",
        "        #Step in the opp direction of gradient\n",
        "        opt.step()\n",
        "\n",
        "        if (batch_num+1) %100==0:\n",
        "            print(f\"Batch {batch_num+1} : {avg_loss/(batch_num)}\")\n",
        "\n",
        "        avg_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} : {avg_loss/len(train_dataset)}\")\n",
        "\n",
        "with open('model_state.pt','wb') as f:\n",
        "    save(clf.state_dict(),f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOS3Z-9MVK8Y",
        "outputId": "7f989e13-3c42-4c48-dd39-608b7df3b176"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "391\n",
            "Batch 100 : 0.596349154156868\n",
            "Batch 200 : 0.611981759718315\n",
            "Batch 300 : 0.6140652079646005\n",
            "Epoch 1 : 0.6103677069744491\n",
            "Batch 100 : 0.5867843937994254\n",
            "Batch 200 : 0.6019211874235815\n",
            "Batch 300 : 0.6049033462203864\n",
            "Epoch 2 : 0.6024484190794513\n",
            "Batch 100 : 0.5704756607913007\n",
            "Batch 200 : 0.5825359295660527\n",
            "Batch 300 : 0.5870951601494117\n",
            "Epoch 3 : 0.5858540710280923\n",
            "Batch 100 : 0.5780697814141861\n",
            "Batch 200 : 0.5814148120245143\n",
            "Batch 300 : 0.5845579729231704\n",
            "Epoch 4 : 0.5841334994949038\n",
            "Batch 100 : 0.5666660248029112\n",
            "Batch 200 : 0.5766241337785769\n",
            "Batch 300 : 0.5744518983523582\n",
            "Epoch 5 : 0.5726010925934443\n",
            "Batch 100 : 0.5450886593322561\n",
            "Batch 200 : 0.5565792834339429\n",
            "Batch 300 : 0.5623992396437604\n",
            "Epoch 6 : 0.5580267184378241\n",
            "Batch 100 : 0.5442735766521608\n",
            "Batch 200 : 0.5471857910479733\n",
            "Batch 300 : 0.5544660037576554\n",
            "Epoch 7 : 0.5534398933810651\n",
            "Batch 100 : 0.5345257839771232\n",
            "Batch 200 : 0.5424205827054067\n",
            "Batch 300 : 0.5458600720434285\n",
            "Epoch 8 : 0.5443475574178769\n",
            "Batch 100 : 0.5428677812369183\n",
            "Batch 200 : 0.5535569799006285\n",
            "Batch 300 : 0.551248936848497\n",
            "Epoch 9 : 0.5489354507849954\n",
            "Batch 100 : 0.5283696865192568\n",
            "Batch 200 : 0.5365863726965746\n",
            "Batch 300 : 0.5436680715618325\n",
            "Epoch 10 : 0.5405827016781664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = datasets.CIFAR10(root='data', download=True, train = False,transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "]))\n",
        "test_dataset = DataLoader(test,32)\n",
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "# Evaluate the model\n",
        "clf.eval()  # Put the model in evaluation model\n",
        "with no_grad():  # Disable gradient calculation for inference\n",
        "    for batch_num, (X, y) in enumerate(test_dataset):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Get predictions\n",
        "        y_pred = clf(X)\n",
        "\n",
        "        # Take the index with the maximum logit value (predicted class)\n",
        "        y_pred = argmax(y_pred, dim=1)\n",
        "\n",
        "        # Update total number of samples\n",
        "        total += y.size(0)\n",
        "\n",
        "        # Count correct predictions\n",
        "        correct += (y_pred == y).sum().item()\n",
        "\n",
        "        # Print progress every 100 batches\n",
        "        if (batch_num + 1) % 100 == 0:\n",
        "            print(f\"Processed {total} samples\")\n",
        "\n",
        "# Print final accuracy\n",
        "print(f\"Accuracy: {correct / total * 100:.2f}%\")\n",
        "print(f\"Total correct predictions: {correct}\")\n",
        "print(f\"Total samples: {total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5PTgmDyaXLn",
        "outputId": "c6132cdb-02e3-4fd4-9eda-3016b7ce5a9a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Processed 3200 samples\n",
            "Processed 6400 samples\n",
            "Processed 9600 samples\n",
            "Accuracy: 80.00%\n",
            "Total correct predictions: 8000\n",
            "Total samples: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dhb0dhBhFlgm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}